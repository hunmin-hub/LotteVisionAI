{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"vit_code.ipynb","provenance":[{"file_id":"1qHc-GaQWP19RI0FJMtvwRuHSaOkD6JK_","timestamp":1616162423860},{"file_id":"17QxNH1pNMKCvE4tD8YUHDk-VDkil--e3","timestamp":1615990352992}],"collapsed_sections":[],"machine_shape":"hm","mount_file_id":"1XbPDLmr9J6Mj7XC3HjE94mGflnOfBCIJ","authorship_tag":"ABX9TyO90AHCrqjedU9+zmkF8BkY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Buiy1AcM1Wc7"},"source":["cd /content/drive/MyDrive/workspace/lotte/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iXDS0G1Jmg6n"},"source":["!unzip ./dataset/LPD_competition.zip -d /content"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vKzNqz-J8Kg6"},"source":["## 라이브러리 import"]},{"cell_type":"code","metadata":{"id":"CUAEgEaQ3qZY"},"source":["!pip install pytorch_pretrained_vit"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NwvFl-QA8KIg"},"source":["import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from pytorch_pretrained_vit import ViT\n","from torchvision import datasets, transforms, models\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","import os\n","from tqdm.auto import tqdm\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","from torchvision import models\n","from glob import glob\n","import cv2\n","from PIL import Image\n","import torch.nn.functional as F\n","from sklearn.model_selection import KFold, StratifiedKFold\n","from torch.optim.lr_scheduler import ReduceLROnPlateau "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lOLmy1bH8R5S"},"source":["## Config Setting"]},{"cell_type":"code","metadata":{"id":"m7hBEsE38Rl6"},"source":["#CONFIG\n","torch.manual_seed(128)\n","BATCH_SIZE=50\n","EPOCHS=40\n","LEARNING_RATE=1e-6\n","#DEVICE\n","print(f'PyTorch Version : [{torch.__version__}]')\n","device=torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","print(f'Device : [{device}]')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oAXOhUln8YtD"},"source":["## Custom Datasets"]},{"cell_type":"code","metadata":{"id":"ZTUb6RoWy98U"},"source":["class LotteDataset(Dataset):\n","  def __init__(self, data_root, train_mode):\n","    super(LotteDataset, self).__init__()\n","    self.train_mode=train_mode\n","\n","    if self.train_mode==False:\n","      self.img_list = glob(os.path.join(data_root, '*.jpg'))\n","      self.img_list.sort(key=lambda x:int(x.split('/')[3][:-4]))\n","    else:\n","      self.img_list = glob(os.path.join(data_root, '*/*.jpg'))\n","      self.train_y=[]\n","      for img_path in self.img_list:\n","        self.train_y.append(int(img_path.split('/')[3]))\n","        \n","    self.len = len(self.img_list)\n","\n","  def __getitem__(self, index):\n","    img_path = self.img_list[index]\n","    if self.train_mode:\n","      label=int(img_path.split('/')[3])\n","    # Image Loading\n","    img = Image.open(img_path)\n","\n","    if self.train_mode:\n","      return img,label\n","    else:\n","      return img\n","\n","  def __len__(self):\n","    return self.len"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8qyZZGVFLZnx"},"source":["class MapTransform(Dataset):\n","    def __init__(self, dataset, transform, train_mode):\n","        self.dataset = dataset\n","        self.transform=transform\n","        self.train_mode=train_mode\n","\n","    def __getitem__(self, index):\n","        if self.train_mode:\n","          return self.transform(self.dataset[index][0]), self.dataset[index][1]\n","        else:\n","          return self.transform(self.dataset[index])\n","\n","    def __len__(self):\n","        return len(self.dataset)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tYbVlrwf8aDx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616716159583,"user_tz":-540,"elapsed":870,"user":{"displayName":"KM KIM","photoUrl":"","userId":"13177087664038437403"}},"outputId":"c33b7fdd-522e-485b-e927-cb6498f56996"},"source":["train_transforms=transforms.Compose([\n","    transforms.RandomChoice([\n","        transforms.ColorJitter(brightness=(1,1.1)),\n","        transforms.ColorJitter(contrast=0.1), \n","        transforms.ColorJitter(saturation=0.1),\n","    ]),\n","    transforms.RandomChoice([\n","        transforms.RandomAffine(degrees=15, translate=(0.2, 0.2), scale=(0.8, 1.2), shear=10, resample=Image.BILINEAR,fill=255),\n","        transforms.RandomCrop((224,224)),\n","    ]),\n","    transforms.ToTensor(),\n","    transforms.Resize((224, 224)),\n","    transforms.Normalize([0.485, 0.456, 0.406],\n","                         [0.229, 0.224, 0.225])\n","])\n","test_transforms=transforms.Compose([transforms.ToTensor(),\n","                                    transforms.Resize((224,224)),\n","                                    transforms.Normalize([0.485, 0.456, 0.406],\n","                                                          [0.229, 0.224, 0.225])])\n","\n","train_data=LotteDataset('/content/train',train_mode=True)\n","test_data=LotteDataset('/content/test',train_mode=False)\n","\n","trans_train_data=MapTransform(train_data,train_transforms,train_mode=True)\n","trans_test_data=MapTransform(test_data,test_transforms,train_mode=False)\n","\n","train_iter=DataLoader(trans_train_data,batch_size=BATCH_SIZE,shuffle=True,num_workers=2)\n","test_iter=DataLoader(trans_test_data,batch_size=BATCH_SIZE,shuffle=False,num_workers=2)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:1315: UserWarning: Argument resample is deprecated and will be removed since v0.10.0. Please, use interpolation instead\n","  \"Argument resample is deprecated and will be removed since v0.10.0. Please, use interpolation instead\"\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"-az7bt28QuAl"},"source":["### CutMix"]},{"cell_type":"code","metadata":{"id":"FkaUs5YJQolI"},"source":["def rand_bbox(W, H, lam):\n","    cut_rat = torch.sqrt(1.0 - lam)\n","    cut_w = (W * cut_rat).type(torch.long)\n","    cut_h = (H * cut_rat).type(torch.long)\n","    # uniform\n","    cx = torch.randint(W, (1,)).to(device)\n","    cy = torch.randint(H, (1,)).to(device)\n","    x1 = torch.clamp(cx - cut_w // 2, 0, W)\n","    y1 = torch.clamp(cy - cut_h // 2, 0, H)\n","    x2 = torch.clamp(cx + cut_w // 2, 0, W)\n","    y2 = torch.clamp(cy + cut_h // 2, 0, H)\n","    return x1, y1, x2, y2\n","\n","\n","def cutmix_data(x, y, alpha=1.0, p=0.5):\n","    if np.random.random() > p:\n","        return x, y, torch.zeros_like(y), 1.0\n","    W, H = x.size(2), x.size(3)\n","    shuffle = torch.randperm(x.size(0)).to(device)\n","    cutmix_x = x\n","\n","    lam = torch.distributions.beta.Beta(alpha, alpha).sample().to(device)\n","\n","    x1, y1, x2, y2 = rand_bbox(W, H, lam)\n","    cutmix_x[:, :, x1:x2, y1:y2] = x[shuffle, :, x1:x2, y1:y2]\n","    # Adjust lambda to match pixel ratio\n","    lam = 1 - ((x2 - x1) * (y2 - y1) / float(W * H)).item()\n","    y_a, y_b = y, y[shuffle]\n","    return cutmix_x, y_a, y_b, lam"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qlM68asZQ3Pm"},"source":["### Label Smooth"]},{"cell_type":"code","metadata":{"id":"x_Qn7fMcQyZ1"},"source":["def loss_fn(outputs, targets):\n","    if len(targets.shape) == 1:\n","        return F.cross_entropy(outputs, targets)\n","    else:\n","        return torch.mean(torch.sum(-targets * F.log_softmax(outputs, dim=1), dim=1))\n","\n","def label_smooth_loss_fn(outputs, targets, epsilon=0.1):\n","    onehot = F.one_hot(targets, 1000).float().to(device)\n","    targets = (1 - epsilon) * onehot + torch.ones(onehot.shape).to(device) * epsilon / 1000\n","    return loss_fn(outputs, targets)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TW46uRAN-4hS"},"source":["## Model Train"]},{"cell_type":"code","metadata":{"id":"PKsj0EMKDUkl"},"source":["def get_submission(Model,data_iter,epoch):\n","  with torch.no_grad():\n","    Model.eval()\n","    pred_label=[]\n","    print(\"Final Testing....\\n\")\n","    for imgs in tqdm(iter(test_iter)):\n","      model_pred=Model(imgs.to(device))\n","\n","      _, y_pred=torch.max(model_pred.data,1)\n","      pred_label.extend(y_pred.tolist())\n","\n","  Model.train()\n","\n","  submission = pd.read_csv('./dataset/sample.csv', encoding = 'utf-8')\n","  submission['prediction'] = pred_label\n","  submission.to_csv('./checkpoint_vit/submission2_'+str(epoch)+'_single.csv', index = False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LSpPoT7prgW5"},"source":["def freeze(Model,idx):\n","  # idx : -1 -> FC Layer 제외하고 동결\n","  # idx : -3 -> 추출기 동결\n","  for m in list(Model.children()):\n","    for param in m.parameters():\n","      param.requires_grad=True\n","\n","  for m in list(Model.children())[:idx]:\n","    for param in m.parameters():\n","      param.requires_grad=False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IFaMb6VDMQhJ"},"source":["#/content/drive/MyDrive/workspace/lotte/checkpoint_vit/ViT_epoch_27.tar\n","model_path='./checkpoint_vit/ViT_epoch_27.tar'\n","\n","Model = ViT('B_16_imagenet1k', pretrained=False,image_size=224)\n","checkpoint=torch.load(model_path)\n","Model.load_state_dict(checkpoint['model_state_dict'])\n","freeze(Model,-3)\n","Model.eval()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CWzVi6EJB7BJ"},"source":["f = open(\"./ViT_Single_trainlog.txt\", 'w')\n","\n","scaler = torch.cuda.amp.GradScaler()\n","optimizer = optim.Adam(Model.parameters(), lr=LEARNING_RATE)\n","scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2,threshold_mode='abs',min_lr=1e-8, verbose=True)\n","loss=label_smooth_loss_fn\n","\n","Model.train()\n","\n","Model.to(device)\n","\n","for epoch in range(EPOCHS) :\n","  loss_val_sum=0\n","  visual_loss_sum=0 # 확인용 Train Loss\n","  for imgs, labels in tqdm(iter(train_iter)):\n","    # Cut mix P=0.5\n","    imgs, labels = imgs.to(device), labels.to(device)\n","    imgs, labels_a, labels_b, lam = cutmix_data(imgs, labels)\n","\n","    # optimizer.zero_grad()\n","    for param in Model.parameters():\n","      param.grad = None\n","    model_pred=Model(imgs)\n","\n","    # Label Smoothing + Cutmix\n","    loss_out = lam * loss(model_pred, labels_a) + (1 - lam) * loss(model_pred, labels_b)\n","    # 확인용 Train Loss\n","    normal_loss_out=lam * loss_fn(model_pred.clone().detach(), labels_a.clone().detach()) + (1 - lam) * loss_fn(model_pred.clone().detach(), labels_b.clone().detach())\n","\n","    scaler.scale(loss_out).backward()\n","    scaler.step(optimizer)\n","    scaler.update()\n","\n","    loss_val_sum+=loss_out\n","    visual_loss_sum+=normal_loss_out\n","\n","  loss_val_avg=loss_val_sum/len(train_iter)\n","  visual_loss_avg=visual_loss_sum/len(train_iter)\n","  get_submission(Model,test_iter,epoch)\n","\n","  print(\"epoch:[%d] train loss smooth:[%.5f] train normal loss:[%.5f] class:[%.5f]\\n\"%(epoch,loss_val_avg,visual_loss_avg,score))\n","  f.write(\"epoch:[%d] train loss smooth:[%.5f] train normal loss:[%.5f]\\n\"%(epoch,loss_val_avg,visual_loss_avg))\n","  print(\"Model Save....\\n\")\n","  torch.save({'model_state_dict': Model.state_dict(),\n","          'optimizer_state_dict': optimizer.state_dict()}, './checkpoint_vit/ViT_epoch_'+str(epoch)+'.tar')\n","  scheduler.step(loss_val_avg) # LR Scheduler\n","f.close()"],"execution_count":null,"outputs":[]}]}